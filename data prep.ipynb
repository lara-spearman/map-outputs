{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f930c7f",
   "metadata": {},
   "source": [
    "## Take clipped data and prep for export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72ba138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a599a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in parish council boundaries\n",
    "gdf = gpd.read_file(\"G:/OS_OpenData/OS_BoundaryLine/OS_BL_Parish_Wilts.shp\")\n",
    "gdf = gdf.to_crs(\"EPSG:27700\")\n",
    "gdf['AreaPC'] = gdf['HECTARES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interim step, read in all csv's and combine\n",
    "df_all_shp = pd.DataFrame({'NAME': [], 'value': [],'groupColumnValue': [],'groupColumnName': [],'mapGroup': [], \"unitName\":[],\"unit\":[],\"datasetName\":[], \"source\":[]})\n",
    "\n",
    "\n",
    "for file in file_info_shp.keys():\n",
    "    df = pd.read_csv(f\"data/clippedData/{file}_v1.csv\")\n",
    "    df_all_shp = pd.concat([df_all_shp, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "acabdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add area of PC to datasets\n",
    "df_all_shp = pd.merge(df_all_shp, gdf[['NAME', 'AreaPC']], how = 'left', on = \"NAME\")\n",
    "# Add value percent column\n",
    "def add_percent(row):\n",
    "    if row['unitName'].lower() == \"area\":\n",
    "        val =  (100*row['value'])/row['AreaPC']\n",
    "    else:\n",
    "        val =   \"\"\n",
    "    return val\n",
    "    \n",
    "df_all_shp['valuePercent'] = df_all_shp.apply(add_percent, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0eef7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rank for each PC on how it compares for each dataset to other PCs\n",
    "df_all_ranked = pd.DataFrame({'NAME': [], 'value': [],'valuePercent': [],'groupColumnValue': [],'groupColumnName': [],'mapGroup': [],'mapName': [], 'rank':[], 'rankPercent':[]})\n",
    "\n",
    "for dataset in df_all_shp.datasetName.unique():\n",
    "    \n",
    "    df_dataset = df_all_shp[df_all_shp['datasetName']==dataset]\n",
    "   # Check if groupColumnValue is null (or na), which means no groups to loop over\n",
    "    if pd.isnull(df_dataset.groupColumnValue.unique()[0])==True:\n",
    "        # Sort PC's by value\n",
    "        df_rank_sorted = df_dataset.sort_values(by = \"value\", ascending=False)\n",
    "        # Add rank column which ranks PC's\n",
    "        df_rank_sorted['rank'] = list(range(1, df_rank_sorted.shape[0]+1))\n",
    "\n",
    "        # Sort PC's by percentage\n",
    "        df_rank_percent_sorted = df_rank_sorted.sort_values(by = \"valuePercent\", ascending=False)\n",
    "        # Rank PC's by percent\n",
    "        df_rank_percent_sorted['rankPercent'] = list(range(1, df_rank_percent_sorted.shape[0]+1))\n",
    "        \n",
    "        df_all_ranked = pd.concat([df_all_ranked, df_rank_percent_sorted])\n",
    "\n",
    "    else:\n",
    "        # If dataset has groupings, need to loop through\n",
    "        for group in df_dataset.groupColumnValue.unique():\n",
    "            # Sort PC's by value\n",
    "            df_rank= df_dataset[df_dataset.groupColumnValue == group]\n",
    "            df_rank_sorted = df_rank.sort_values(by = \"value\", ascending=False)\n",
    "            # Add rank column which ranks PC's\n",
    "            df_rank_sorted['rank'] = list(range(1, df_rank_sorted.shape[0]+1))\n",
    "\n",
    "             # Sort PC's by percentage\n",
    "            df_rank_percent_sorted = df_rank_sorted.sort_values(by = \"valuePercent\", ascending=False)\n",
    "            # Rank PC's by percent\n",
    "            df_rank_percent_sorted['rankPercent'] = list(range(1, df_rank_percent_sorted.shape[0]+1))\n",
    "            \n",
    "            df_all_ranked = pd.concat([df_all_ranked, df_rank_percent_sorted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "046ed37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_ranked['unit'] = df_all_ranked['unit'].replace(\"HECTARES\", \"Ha\")\n",
    "df_all_ranked['unit'] = df_all_ranked['unit'].replace(\"Area (ha)\", \"Ha\")\n",
    "df_all_ranked['unit'] = df_all_ranked['unit'].replace(\"METERS\", \"Metres\")\n",
    "df_all_ranked['unit'] = df_all_ranked['unit'].replace(\"Count\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12adaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_ranked.to_csv(\"data/outputClippedData.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map-outputs",
   "language": "python",
   "name": "map-outputs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
